{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07b: Extended sensitivity analysis\n",
    "\n",
    "In this script, we perform sensitivity analysis by sampling technosphere, biosphere, and weighting (monetization) inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lca_sensitivity_analysis import *\n",
    "\n",
    "import xarray as xr\n",
    "from scipy import sparse\n",
    "from time import time\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run common_definitions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw.projects.set_current(BW_PROJECTNAME)\n",
    "output_fp = \"../output/\" + BW_PROJECTNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select scenario and year and further parameter choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scen = \"SSP2-NPi\"\n",
    "year = 2030\n",
    "substring = \"{}_{}\".format(scen, str(year))\n",
    "db = bw.Database([name for name in bw.databases if substring in name][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select technologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../mappings/technology_selection_energy_provision_v4.csv\")\n",
    "long2short = dict(zip(list(df[\"ecoinvent name\"]), list(df[\"short name\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_names = list(df[\"ecoinvent name\"].unique())\n",
    "db_subset = [act for act in db if act[\"name\"] in subset_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_global(actlist):\n",
    "    locations = [act[\"location\"] for act in actlist]\n",
    "\n",
    "    return any(x in locations for x in [\"RoW\", \"GLO\", \"World\"])\n",
    "\n",
    "def select_region(actlist):\n",
    "    locations = [act[\"location\"] for act in actlist]\n",
    "\n",
    "    if contains_global(actlist):\n",
    "        if \"GLO\" in locations:\n",
    "            return actlist[locations.index(\"GLO\")]\n",
    "        elif \"World\" in locations:\n",
    "            return actlist[locations.index(\"World\")]\n",
    "        else:\n",
    "            return actlist[locations.index(\"RoW\")]\n",
    "    else:\n",
    "        # choose alphabetically first location (need a deterministic selection)\n",
    "        first_location = sorted(locations)[0]\n",
    "        return actlist[locations.index(first_location)]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 45 activities found in sector electricity production in database SSP2-NPi_2030\n",
      "A total of 17 activities found in sector district or industrial heat in database SSP2-NPi_2030\n",
      "A total of 48 activities found in sector liquids in database SSP2-NPi_2030\n",
      "A total of 18 activities found in sector hydrogen and gases in database SSP2-NPi_2030\n",
      "A total of 9 activities found in sector solids in database SSP2-NPi_2030\n",
      "A total of 12 activities found in sector residential heating in database SSP2-NPi_2030\n"
     ]
    }
   ],
   "source": [
    "activities = {}\n",
    "\n",
    "for sector in df[\"sector\"].unique():\n",
    "    sel = df[df[\"sector\"] == sector]\n",
    "    all_matches = []\n",
    "    for name, product in zip(list(sel[\"ecoinvent name\"]), list(sel[\"reference product\"])):\n",
    "        matches = [act for act in db_subset if act[\"name\"] == name and act[\"reference product\"] == product]\n",
    "        if len(matches) == 0:\n",
    "            print(\"No matches for {}, {}\".format(name, product))\n",
    "        sel = select_region(matches)\n",
    "        # if not contains_global(matches):\n",
    "        #     print(\"No global dataset for {}, {}. Location {} selected.\".format(name, product, sel[\"location\"]))\n",
    "        # print(\"\\t{} activities found for {}, {} in database {}\".format(len(matches), name, product, substring))\n",
    "        all_matches.append(sel)\n",
    "    print(\"A total of {} activities found in sector {} in database {}\".format(len(all_matches), sector, substring))\n",
    "    activities[sector] = all_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get methods and weights (monetization factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfs_mc_sample = xr.open_dataarray(\"../data/mfs_monte_carlo_sample_euro{}_larger.nc\".format(str(EURO_REF_YEAR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_total = mfs_mc_sample.sum(dim=\"impact category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [m for m in list(bw.methods) if \", \".join(list(m)) in weights_total.coords[\"LCIA method\"].values]\n",
    "\n",
    "ALL_WEIGHTS = weights_total.to_pandas().T.loc[[\", \".join(list(m)) for m in methods]].to_numpy()\n",
    "mean_weights = np.mean(ALL_WEIGHTS, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-factor at a time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gsa_ofat(act, methods, mean_weights, Nsamples, print_to_console=True):\n",
    "    # set up LCA\n",
    "    fu = {act: 1}\n",
    "    lca = bw.LCA(fu)\n",
    "    lca.lci()\n",
    "\n",
    "    # biosphere variation\n",
    "    t0 = time()\n",
    "    bio_rng = MCRandomNumberGenerator(lca.bio_params)\n",
    "    bio_results = []\n",
    "    for i in range(Nsamples):\n",
    "        lca.rebuild_biosphere_matrix(bio_rng.next())\n",
    "\n",
    "        count = len(lca.activity_dict)\n",
    "        lca.inventory = lca.biosphere_matrix * \\\n",
    "            sparse.spdiags([lca.supply_array], [0], count, count)\n",
    "        \n",
    "        temp = []\n",
    "        for m in methods:\n",
    "            lca.switch_method(m)\n",
    "            lca.lcia_calculation()\n",
    "            temp.append(lca.score)\n",
    "\n",
    "        bio_results.append(np.sum(np.array(temp) * mean_weights))\n",
    "        print(\"{}: Biosphere: Run {} of {} done.\".format(str(act), i+1, Nsamples))\n",
    "    t1 = time()\n",
    "\n",
    "    if print_to_console:\n",
    "        print(\"{}: Biosphere variation runs done in {} seconds\".format(str(act), round(t1-t0, 2)))\n",
    "\n",
    "    # technosphere variation\n",
    "    t0 = time()\n",
    "    tech_rng = MCRandomNumberGenerator(lca.tech_params)\n",
    "    tech_results = []\n",
    "    for i in range(Nsamples):\n",
    "        t2 = time()\n",
    "        lca.rebuild_technosphere_matrix(tech_rng.next())\n",
    "\n",
    "        t3 = time()\n",
    "\n",
    "        lca.redo_lci(fu)\n",
    "\n",
    "        t4 = time()\n",
    "\n",
    "        temp = []\n",
    "        for m in methods:\n",
    "            lca.switch_method(m)\n",
    "            lca.lcia_calculation()\n",
    "            temp.append(lca.score)\n",
    "\n",
    "        tech_results.append(np.sum(np.array(temp) * mean_weights))\n",
    "        print(\"{}: Technosphere: Run {} of {} done (rebuilding: {} seconds, lci: {} seconds)\".format(str(act), i+1, Nsamples, t3-t2, t4-t3))\n",
    "    t1 = time()\n",
    "\n",
    "    if print_to_console:\n",
    "        print(\"{}: Technosphere variation runs done in {} seconds\".format(str(act), t1-t0))\n",
    "\n",
    "    return {\n",
    "        \"technosphere\": tech_results,\n",
    "        \"biosphere\": bio_results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gsa_ofat_multi(actlist, mean_cost_method, Nsamples):\n",
    "    # set up LCA\n",
    "    fu = {actlist[0]: 1}\n",
    "    lca = bw.LCA(fu, mean_cost_method)\n",
    "    lca.lci()\n",
    "    lca.lcia()\n",
    "\n",
    "    ## Biosphere variation ##\n",
    "    # calculate supply arrays for all activities\n",
    "    lca.decompose_technosphere()\n",
    "    supply_arrays = []\n",
    "    count = len(lca.activity_dict)\n",
    "    for act in actlist:\n",
    "        lca.redo_lci({act: 1})\n",
    "        supply_arrays.append(lca.supply_array)\n",
    "\n",
    "    bio_rng = MCRandomNumberGenerator(lca.bio_params)\n",
    "    bio_results = np.zeros((len(actlist), Nsamples))\n",
    "    for j in range(Nsamples):\n",
    "        lca.rebuild_biosphere_matrix(bio_rng.next())\n",
    "        for i, supply in enumerate(supply_arrays):\n",
    "            lca.inventory = lca.biosphere_matrix * \\\n",
    "                    sparse.spdiags([supply], [0], count, count)\n",
    "            lca.lcia_calculation()\n",
    "            bio_results[i, j] = lca.score\n",
    "            print(\"Biosphere variation: Activity {} of {}, run {} of {} done.\".format(i+1, len(actlist), j+1, Nsamples))\n",
    "\n",
    "    # technosphere variation\n",
    "    # set up LCA again\n",
    "    fu = {actlist[0]: 1}\n",
    "    lca = bw.LCA(fu, mean_cost_method)\n",
    "    lca.lci()\n",
    "    lca.lcia()\n",
    "\n",
    "    tech_rng = MCRandomNumberGenerator(lca.tech_params)\n",
    "    tech_results = np.zeros((len(actlist), Nsamples))\n",
    "    for j in range(Nsamples):\n",
    "        lca.rebuild_technosphere_matrix(tech_rng.next())\n",
    "        lca.decompose_technosphere()\n",
    "\n",
    "        for i, act in enumerate(actlist):\n",
    "            lca.redo_lci({act: 1})\n",
    "            lca.lcia_calculation()\n",
    "            tech_results[i, j] = lca.score\n",
    "            print(\"Technosphere variation: Activity {} of {}, Run {} of {} done.\".format(i+1, len(actlist), j+1, Nsamples))\n",
    "\n",
    "    return {\n",
    "        \"technosphere\": tech_results,\n",
    "        \"biosphere\": bio_results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_method = (\"Monte Carlo monetization (larger sample)\", \"mean total costs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_activities = []\n",
    "all_sectors = []\n",
    "for sec, a in activities.items():\n",
    "    all_activities += a\n",
    "    all_sectors += len(a) * [sec,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "short2location = {}\n",
    "for act in all_activities:\n",
    "    tech = long2short[act[\"name\"]]\n",
    "    loc = act[\"location\"]\n",
    "    short2location[tech] = loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_multi_all = gsa_ofat_multi(all_activities, cost_method, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist = []\n",
    "for stage, results in scores_multi_all.items():\n",
    "    for i, act in enumerate(all_activities):\n",
    "        y = results[i,:]\n",
    "        df = pd.DataFrame({\n",
    "            \"output value\": y,\n",
    "        })\n",
    "        df[\"stage\"] = stage\n",
    "        df[\"sample index\"] = np.arange(len(y))\n",
    "        df[\"short name\"] = long2short[act[\"name\"]]\n",
    "        df[\"sector\"] = all_sectors[i]\n",
    "        df[\"scenario\"] = scen\n",
    "        df[\"year\"] = year\n",
    "        df[\"location\"] = act[\"location\"]\n",
    "        dflist.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.concat(dflist, axis=0, ignore_index=True)\n",
    "output.to_csv(\"gsa_ofat_all_sample1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cs = {\"inv\": [{act: 1} for act in all_activities], \"ia\": methods}\n",
    "bw.calculation_setups[\"GSA\"] = new_cs\n",
    "\n",
    "mc = bw.MultiLCA(\"GSA\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = np.matmul(mc.results, weights_total.to_pandas()[[\", \".join(list(m)) for m in methods]].to_numpy().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []\n",
    "for act, sector in zip(all_activities, all_sectors):\n",
    "    tech = long2short[act[\"name\"]]\n",
    "    idx.append(str((tech, sector)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.DataArray(\n",
    "    costs,\n",
    "    coords={\n",
    "        \"activity key\": idx,\n",
    "        \"sample index\": list(range(costs.shape[1]))\n",
    "    }\n",
    ").to_netcdf(output_fp+\"/gsa_ofat_all_costs.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate variances and sensitivity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output value</th>\n",
       "      <th>stage</th>\n",
       "      <th>sample index</th>\n",
       "      <th>short name</th>\n",
       "      <th>sector</th>\n",
       "      <th>scenario</th>\n",
       "      <th>year</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.102113</td>\n",
       "      <td>technosphere</td>\n",
       "      <td>0</td>\n",
       "      <td>BIGCC</td>\n",
       "      <td>electricity production</td>\n",
       "      <td>SSP2-NPi</td>\n",
       "      <td>2030</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.105272</td>\n",
       "      <td>technosphere</td>\n",
       "      <td>1</td>\n",
       "      <td>BIGCC</td>\n",
       "      <td>electricity production</td>\n",
       "      <td>SSP2-NPi</td>\n",
       "      <td>2030</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.102952</td>\n",
       "      <td>technosphere</td>\n",
       "      <td>2</td>\n",
       "      <td>BIGCC</td>\n",
       "      <td>electricity production</td>\n",
       "      <td>SSP2-NPi</td>\n",
       "      <td>2030</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.101132</td>\n",
       "      <td>technosphere</td>\n",
       "      <td>3</td>\n",
       "      <td>BIGCC</td>\n",
       "      <td>electricity production</td>\n",
       "      <td>SSP2-NPi</td>\n",
       "      <td>2030</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.100353</td>\n",
       "      <td>technosphere</td>\n",
       "      <td>4</td>\n",
       "      <td>BIGCC</td>\n",
       "      <td>electricity production</td>\n",
       "      <td>SSP2-NPi</td>\n",
       "      <td>2030</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595995</th>\n",
       "      <td>0.021843</td>\n",
       "      <td>biosphere</td>\n",
       "      <td>1995</td>\n",
       "      <td>diffusion adsorption heat pump</td>\n",
       "      <td>residential heating</td>\n",
       "      <td>SSP2-NPi</td>\n",
       "      <td>2030</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595996</th>\n",
       "      <td>0.025134</td>\n",
       "      <td>biosphere</td>\n",
       "      <td>1996</td>\n",
       "      <td>diffusion adsorption heat pump</td>\n",
       "      <td>residential heating</td>\n",
       "      <td>SSP2-NPi</td>\n",
       "      <td>2030</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595997</th>\n",
       "      <td>0.022911</td>\n",
       "      <td>biosphere</td>\n",
       "      <td>1997</td>\n",
       "      <td>diffusion adsorption heat pump</td>\n",
       "      <td>residential heating</td>\n",
       "      <td>SSP2-NPi</td>\n",
       "      <td>2030</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595998</th>\n",
       "      <td>0.018084</td>\n",
       "      <td>biosphere</td>\n",
       "      <td>1998</td>\n",
       "      <td>diffusion adsorption heat pump</td>\n",
       "      <td>residential heating</td>\n",
       "      <td>SSP2-NPi</td>\n",
       "      <td>2030</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595999</th>\n",
       "      <td>0.020782</td>\n",
       "      <td>biosphere</td>\n",
       "      <td>1999</td>\n",
       "      <td>diffusion adsorption heat pump</td>\n",
       "      <td>residential heating</td>\n",
       "      <td>SSP2-NPi</td>\n",
       "      <td>2030</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>596000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        output value         stage  sample index  \\\n",
       "0           0.102113  technosphere             0   \n",
       "1           0.105272  technosphere             1   \n",
       "2           0.102952  technosphere             2   \n",
       "3           0.101132  technosphere             3   \n",
       "4           0.100353  technosphere             4   \n",
       "...              ...           ...           ...   \n",
       "595995      0.021843     biosphere          1995   \n",
       "595996      0.025134     biosphere          1996   \n",
       "595997      0.022911     biosphere          1997   \n",
       "595998      0.018084     biosphere          1998   \n",
       "595999      0.020782     biosphere          1999   \n",
       "\n",
       "                            short name                  sector  scenario  \\\n",
       "0                                BIGCC  electricity production  SSP2-NPi   \n",
       "1                                BIGCC  electricity production  SSP2-NPi   \n",
       "2                                BIGCC  electricity production  SSP2-NPi   \n",
       "3                                BIGCC  electricity production  SSP2-NPi   \n",
       "4                                BIGCC  electricity production  SSP2-NPi   \n",
       "...                                ...                     ...       ...   \n",
       "595995  diffusion adsorption heat pump     residential heating  SSP2-NPi   \n",
       "595996  diffusion adsorption heat pump     residential heating  SSP2-NPi   \n",
       "595997  diffusion adsorption heat pump     residential heating  SSP2-NPi   \n",
       "595998  diffusion adsorption heat pump     residential heating  SSP2-NPi   \n",
       "595999  diffusion adsorption heat pump     residential heating  SSP2-NPi   \n",
       "\n",
       "        year location  \n",
       "0       2030    World  \n",
       "1       2030    World  \n",
       "2       2030    World  \n",
       "3       2030    World  \n",
       "4       2030    World  \n",
       "...      ...      ...  \n",
       "595995  2030    World  \n",
       "595996  2030    World  \n",
       "595997  2030    World  \n",
       "595998  2030    World  \n",
       "595999  2030    World  \n",
       "\n",
       "[596000 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.read_csv(output_fp+\"/gsa_ofat_all_outputsamples.csv\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_quantiles(df, idx, qidx, col, low, high):\n",
    "    dfnew = df.set_index(idx)\n",
    "    low = df.groupby(qidx)[col].quantile(low).rename(\"low\")\n",
    "    high = df.groupby(qidx)[col].quantile(high).rename(\"high\")\n",
    "\n",
    "    dfnew = dfnew.join(low)\n",
    "    dfnew = dfnew.join(high).reset_index()\n",
    "\n",
    "    sel = dfnew[dfnew[col] <= dfnew[\"high\"]]\n",
    "    sel = sel[sel[col] >= sel[\"low\"]]\n",
    "\n",
    "    return sel\n",
    "\n",
    "def calculate_variances(df, chunks=1):\n",
    "    dfnew = df.copy()\n",
    "    Nsamples = dfnew[\"sample index\"].max() + 1\n",
    "    dfnew[\"chunk index\"] = dfnew[\"sample index\"] // (Nsamples // chunks)\n",
    "    \n",
    "    return dfnew.groupby([\"short name\", \"sector\", \"stage\", \"chunk index\"]).agg({\"output value\": np.var})\n",
    "\n",
    "def calculate_stds(df, chunks=1):\n",
    "    dfnew = df.copy()\n",
    "    Nsamples = dfnew[\"sample index\"].max() + 1\n",
    "    dfnew[\"chunk index\"] = dfnew[\"sample index\"] // (Nsamples // chunks)\n",
    "    \n",
    "    return dfnew.groupby([\"short name\", \"sector\", \"stage\", \"chunk index\"]).agg({\"output value\": np.std})\n",
    "\n",
    "def normalize_column(df, col, values, new_value_name):\n",
    "    idx = list(set(df.columns) - {col}- {values})\n",
    "    a = df.pivot(index=idx, columns=col, values=values)\n",
    "\n",
    "    return a.divide(a.sum(axis=1), axis=0).melt(\n",
    "        ignore_index=False, value_name=new_value_name).reset_index()\n",
    "\n",
    "def cv(x):\n",
    "    return np.std(x) / np.mean(x)\n",
    "\n",
    "def calculate_cvs(df, chunks=1):\n",
    "    dfnew = df.copy()\n",
    "    Nsamples = dfnew[\"sample index\"].max() + 1\n",
    "    dfnew[\"chunk index\"] = dfnew[\"sample index\"] // (Nsamples // chunks)\n",
    "    \n",
    "    return dfnew.groupby([\"short name\", \"sector\", \"stage\", \"chunk index\"]).agg({\"output value\": cv})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\davidba\\AppData\\Local\\Temp\\ipykernel_13456\\2324570165.py:19: FutureWarning: The provided callable <function var at 0x000001AB14D3F880> is currently using SeriesGroupBy.var. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"var\" instead.\n",
      "  return dfnew.groupby([\"short name\", \"sector\", \"stage\", \"chunk index\"]).agg({\"output value\": np.var})\n",
      "C:\\Users\\davidba\\AppData\\Local\\Temp\\ipykernel_13456\\2324570165.py:19: FutureWarning: The provided callable <function var at 0x000001AB14D3F880> is currently using SeriesGroupBy.var. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"var\" instead.\n",
      "  return dfnew.groupby([\"short name\", \"sector\", \"stage\", \"chunk index\"]).agg({\"output value\": np.var})\n",
      "C:\\Users\\davidba\\AppData\\Local\\Temp\\ipykernel_13456\\2324570165.py:19: FutureWarning: The provided callable <function var at 0x000001AB14D3F880> is currently using SeriesGroupBy.var. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"var\" instead.\n",
      "  return dfnew.groupby([\"short name\", \"sector\", \"stage\", \"chunk index\"]).agg({\"output value\": np.var})\n",
      "C:\\Users\\davidba\\AppData\\Local\\Temp\\ipykernel_13456\\2324570165.py:19: FutureWarning: The provided callable <function var at 0x000001AB14D3F880> is currently using SeriesGroupBy.var. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"var\" instead.\n",
      "  return dfnew.groupby([\"short name\", \"sector\", \"stage\", \"chunk index\"]).agg({\"output value\": np.var})\n",
      "C:\\Users\\davidba\\AppData\\Local\\Temp\\ipykernel_13456\\2324570165.py:19: FutureWarning: The provided callable <function var at 0x000001AB14D3F880> is currently using SeriesGroupBy.var. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"var\" instead.\n",
      "  return dfnew.groupby([\"short name\", \"sector\", \"stage\", \"chunk index\"]).agg({\"output value\": np.var})\n"
     ]
    }
   ],
   "source": [
    "filter_levels = [0, 0.01, 0.02, 0.05, 0.1]\n",
    "\n",
    "dflist = []\n",
    "for fl in filter_levels:\n",
    "    filtered_data = filter_by_quantiles(\n",
    "                                output,\n",
    "                                [\"short name\", \"sector\", \"stage\", \"sample index\"],\n",
    "                                [\"short name\", \"sector\", \"stage\"],\n",
    "                                \"output value\",\n",
    "                                fl,\n",
    "                                1-fl)\n",
    "    \n",
    "    df_var1 = calculate_variances(filtered_data).reset_index().drop(columns=\"chunk index\").rename(columns={\"output value\": \"variance\"})\n",
    "    df_var2 = pd.DataFrame({\n",
    "        \"variance\": np.var(costs, axis=1),\n",
    "        \"short name\": [long2short[act[\"name\"]] for act in all_activities],\n",
    "        \"sector\": all_sectors\n",
    "    })\n",
    "    df_var2[\"stage\"] = \"monetization\"\n",
    "\n",
    "    df_var = pd.concat((df_var1, df_var2), ignore_index=True)\n",
    "    df_var[\"scenario\"] = scen\n",
    "    df_var[\"year\"] = year\n",
    "    df_var[\"location\"] = df_var[\"short name\"].apply(lambda x: short2location[x])\n",
    "\n",
    "    df_sens = normalize_column(\n",
    "        df_var, \"stage\", \"variance\", \"sensitivity\"\n",
    "        ).set_index(\n",
    "            [\"short name\", \"sector\", \"stage\"]\n",
    "            ).sort_index().reset_index()\n",
    "    \n",
    "    df_sens[\"filter level\"] = fl\n",
    "    dflist.append(df_sens)\n",
    "\n",
    "df_sens_all = pd.concat(dflist, ignore_index=False)\n",
    "df_sens_all.to_csv(output_fp+\"/gsa_ofat_all_sensdata_w_filters.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_levels = [0, 0.01, 0.02, 0.05, 0.1]\n",
    "\n",
    "dflist = []\n",
    "for fl in filter_levels:\n",
    "    filtered_data = filter_by_quantiles(\n",
    "                                output,\n",
    "                                [\"short name\", \"sector\", \"stage\", \"sample index\"],\n",
    "                                [\"short name\", \"sector\", \"stage\"],\n",
    "                                \"output value\",\n",
    "                                fl,\n",
    "                                1-fl)\n",
    "    \n",
    "    df_cv1 = calculate_cvs(filtered_data).reset_index().drop(columns=\"chunk index\").rename(columns={\"output value\": \"CV\"})\n",
    "    df_cv2 = pd.DataFrame({\n",
    "        \"CV\": np.apply_along_axis(cv, 1, costs),\n",
    "        \"short name\": [long2short[act[\"name\"]] for act in all_activities],\n",
    "        \"sector\": all_sectors\n",
    "    })\n",
    "    df_cv2[\"stage\"] = \"monetization\"\n",
    "\n",
    "    df_cv = pd.concat((df_cv1, df_cv2), ignore_index=True)\n",
    "    df_cv[\"scenario\"] = scen\n",
    "    df_cv[\"year\"] = year\n",
    "    df_cv[\"location\"] = df_var[\"short name\"].apply(lambda x: short2location[x])\n",
    "    \n",
    "    df_cv[\"filter level\"] = fl\n",
    "    dflist.append(df_cv)\n",
    "\n",
    "df_cv_all = pd.concat(dflist, ignore_index=False)\n",
    "df_cv_all.to_csv(output_fp+\"/gsa_ofat_all_cvdata_w_filters.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rolling_variances(df):\n",
    "    Nsamples = df[\"sample index\"].max() + 1\n",
    "    \n",
    "    return df.groupby([\"short name\", \"sector\", \"stage\"]).rolling(Nsamples, min_periods=2).var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without quantile filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\davidba\\AppData\\Local\\Temp\\ipykernel_25628\\3366105626.py:6: FutureWarning: The provided callable <function var at 0x000001627BA6F880> is currently using SeriesGroupBy.var. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"var\" instead.\n",
      "  return dfnew.groupby([\"short name\", \"sector\", \"stage\", \"chunk index\"]).agg({\"output value\": np.var})\n"
     ]
    }
   ],
   "source": [
    "df_var1 = calculate_variances(output).reset_index().drop(columns=\"chunk index\").rename(columns={\"output value\": \"variance\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var2 = pd.DataFrame({\n",
    "    \"variance\": np.var(costs, axis=1),\n",
    "    \"short name\": [long2short[act[\"name\"]] for act in all_activities],\n",
    "    \"sector\": all_sectors\n",
    "})\n",
    "df_var2[\"stage\"] = \"monetization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var = pd.concat((df_var1, df_var2), ignore_index=True)\n",
    "df_var[\"scenario\"] = scen\n",
    "df_var[\"year\"] = year\n",
    "df_var[\"location\"] = df_var[\"short name\"].apply(lambda x: short2location[x])\n",
    "df_var.to_csv(output_fp+\"/gsa_ofat_all_vardata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens = normalize_column(\n",
    "        df_var, \"stage\", \"variance\", \"sensitivity\"\n",
    "        ).set_index(\n",
    "            [\"short name\", \"sector\", \"stage\"]\n",
    "            ).sort_index().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens.to_csv(output_fp+\"/gsa_ofat_all_sensdata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also try standard deviation instead of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\davidba\\AppData\\Local\\Temp\\ipykernel_18208\\2285359168.py:26: FutureWarning: The provided callable <function std at 0x000002740C05B760> is currently using SeriesGroupBy.std. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"std\" instead.\n",
      "  return dfnew.groupby([\"short name\", \"sector\", \"stage\", \"chunk index\"]).agg({\"output value\": np.std})\n"
     ]
    }
   ],
   "source": [
    "df_std1 = calculate_stds(output).reset_index().drop(columns=\"chunk index\").rename(columns={\"output value\": \"std\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std2 = pd.DataFrame({\n",
    "    \"std\": np.std(costs, axis=1),\n",
    "    \"short name\": [long2short[act[\"name\"]] for act in all_activities],\n",
    "    \"sector\": all_sectors\n",
    "})\n",
    "df_std2[\"stage\"] = \"monetization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std = pd.concat((df_std1, df_std2), ignore_index=True)\n",
    "df_std[\"scenario\"] = scen\n",
    "df_std[\"year\"] = year\n",
    "df_std[\"location\"] = df_std[\"short name\"].apply(lambda x: short2location[x])\n",
    "df_std.to_csv(output_fp+\"/gsa_ofat_all_stddata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens_std = normalize_column(\n",
    "        df_std, \"stage\", \"std\", \"sensitivity\"\n",
    "        ).set_index(\n",
    "            [\"short name\", \"sector\", \"stage\"]\n",
    "            ).sort_index().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens_std.to_csv(output_fp+\"/gsa_ofat_all_sensdata_std.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "costs_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
